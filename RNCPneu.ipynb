{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb0e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29a7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = Sequential()\n",
    "classificador.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classificador.add(BatchNormalization())\n",
    "classificador.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classificador.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classificador.add(BatchNormalization())\n",
    "classificador.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classificador.add(Flatten())\n",
    "\n",
    "classificador.add(Dense(units = 128, activation = 'relu'))\n",
    "classificador.add(Dropout(0.2))\n",
    "classificador.add(Dense(units = 128, activation = 'relu'))\n",
    "classificador.add(Dropout(0.2))\n",
    "classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64ed55a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 703 images belonging to 2 classes.\n",
      "Found 325 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "117/117 [==============================] - 35s 299ms/step - loss: 0.2596 - accuracy: 0.8962 - val_loss: 0.5390 - val_accuracy: 0.7477\n",
      "Epoch 2/30\n",
      "117/117 [==============================] - 35s 296ms/step - loss: 0.2641 - accuracy: 0.8905 - val_loss: 0.6258 - val_accuracy: 0.7354\n",
      "Epoch 3/30\n",
      "117/117 [==============================] - 35s 295ms/step - loss: 0.2363 - accuracy: 0.8990 - val_loss: 0.6325 - val_accuracy: 0.7354\n",
      "Epoch 4/30\n",
      "117/117 [==============================] - 34s 293ms/step - loss: 0.2302 - accuracy: 0.9033 - val_loss: 0.9519 - val_accuracy: 0.7108\n",
      "Epoch 5/30\n",
      "117/117 [==============================] - 35s 297ms/step - loss: 0.2484 - accuracy: 0.9104 - val_loss: 0.5690 - val_accuracy: 0.7692\n",
      "Epoch 6/30\n",
      "117/117 [==============================] - 35s 296ms/step - loss: 0.2199 - accuracy: 0.9047 - val_loss: 1.2223 - val_accuracy: 0.6215\n",
      "Epoch 7/30\n",
      "117/117 [==============================] - 35s 296ms/step - loss: 0.2583 - accuracy: 0.9161 - val_loss: 0.7664 - val_accuracy: 0.6462\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - 35s 296ms/step - loss: 0.2199 - accuracy: 0.9203 - val_loss: 0.9167 - val_accuracy: 0.6985\n",
      "Epoch 9/30\n",
      "117/117 [==============================] - 35s 296ms/step - loss: 0.2359 - accuracy: 0.8947 - val_loss: 0.6758 - val_accuracy: 0.7538\n",
      "Epoch 10/30\n",
      "117/117 [==============================] - 34s 295ms/step - loss: 0.2065 - accuracy: 0.9061 - val_loss: 0.9539 - val_accuracy: 0.7046\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - 34s 293ms/step - loss: 0.2053 - accuracy: 0.9218 - val_loss: 0.7886 - val_accuracy: 0.7385\n",
      "Epoch 12/30\n",
      "117/117 [==============================] - 34s 294ms/step - loss: 0.1986 - accuracy: 0.9232 - val_loss: 0.5875 - val_accuracy: 0.7415\n",
      "Epoch 13/30\n",
      "117/117 [==============================] - 34s 295ms/step - loss: 0.1545 - accuracy: 0.9403 - val_loss: 1.2070 - val_accuracy: 0.6246\n",
      "Epoch 14/30\n",
      "117/117 [==============================] - 34s 294ms/step - loss: 0.1851 - accuracy: 0.9275 - val_loss: 0.6369 - val_accuracy: 0.7815\n",
      "Epoch 15/30\n",
      "117/117 [==============================] - 34s 291ms/step - loss: 0.2126 - accuracy: 0.9289 - val_loss: 0.5410 - val_accuracy: 0.7908\n",
      "Epoch 16/30\n",
      "117/117 [==============================] - 35s 296ms/step - loss: 0.2052 - accuracy: 0.9303 - val_loss: 0.6236 - val_accuracy: 0.7692\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - 34s 294ms/step - loss: 0.1620 - accuracy: 0.9360 - val_loss: 1.4741 - val_accuracy: 0.5938\n",
      "Epoch 18/30\n",
      "117/117 [==============================] - 34s 293ms/step - loss: 0.1611 - accuracy: 0.9388 - val_loss: 0.8066 - val_accuracy: 0.7169\n",
      "Epoch 19/30\n",
      "117/117 [==============================] - 34s 294ms/step - loss: 0.1530 - accuracy: 0.9331 - val_loss: 0.9060 - val_accuracy: 0.6954\n",
      "Epoch 20/30\n",
      "117/117 [==============================] - 35s 297ms/step - loss: 0.1794 - accuracy: 0.9331 - val_loss: 0.8412 - val_accuracy: 0.7292\n",
      "Epoch 21/30\n",
      "117/117 [==============================] - 35s 301ms/step - loss: 0.1744 - accuracy: 0.9289 - val_loss: 0.6045 - val_accuracy: 0.7908\n",
      "Epoch 22/30\n",
      "117/117 [==============================] - 35s 301ms/step - loss: 0.1475 - accuracy: 0.9331 - val_loss: 0.8426 - val_accuracy: 0.6954\n",
      "Epoch 23/30\n",
      "117/117 [==============================] - 35s 297ms/step - loss: 0.1400 - accuracy: 0.9531 - val_loss: 1.4290 - val_accuracy: 0.6769\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - 35s 299ms/step - loss: 0.1657 - accuracy: 0.9360 - val_loss: 0.7352 - val_accuracy: 0.7538\n",
      "Epoch 25/30\n",
      "117/117 [==============================] - 34s 294ms/step - loss: 0.1311 - accuracy: 0.9616 - val_loss: 0.8125 - val_accuracy: 0.7446\n",
      "Epoch 26/30\n",
      "117/117 [==============================] - 34s 291ms/step - loss: 0.1196 - accuracy: 0.9687 - val_loss: 1.0040 - val_accuracy: 0.6954\n",
      "Epoch 27/30\n",
      "117/117 [==============================] - 34s 294ms/step - loss: 0.1239 - accuracy: 0.9502 - val_loss: 1.1588 - val_accuracy: 0.6892\n",
      "Epoch 28/30\n",
      "117/117 [==============================] - 34s 292ms/step - loss: 0.1251 - accuracy: 0.9573 - val_loss: 0.8492 - val_accuracy: 0.7477\n",
      "Epoch 29/30\n",
      "117/117 [==============================] - 34s 290ms/step - loss: 0.1522 - accuracy: 0.9459 - val_loss: 1.2535 - val_accuracy: 0.6831\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 34s 294ms/step - loss: 0.1500 - accuracy: 0.9531 - val_loss: 0.7616 - val_accuracy: 0.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6a23e9700>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerador_treinamento = ImageDataGenerator(rescale = 1./255,\n",
    "                                         rotation_range = 7,\n",
    "                                         horizontal_flip = True,\n",
    "                                         shear_range = 0.2,\n",
    "                                         height_shift_range = 0.07)\n",
    "                                         #zoom_range = 0.5')\n",
    "\n",
    "gerador_teste = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "base_treinamento = gerador_treinamento.flow_from_directory(r'archive\\Tire Textures\\training_data',\n",
    "                                                           target_size = (64, 64),\n",
    "                                                           batch_size = 6,\n",
    "                                                           class_mode = 'binary')\n",
    "\n",
    "base_teste = gerador_teste.flow_from_directory(r'archive\\Tire Textures\\testing_data',\n",
    "                                               target_size = (64, 64),\n",
    "                                               batch_size = 6,\n",
    "                                               class_mode = 'binary')\n",
    "\n",
    "classificador.fit(base_treinamento, steps_per_epoch = 703 / 6,\n",
    "                            epochs = 30, validation_data = base_teste,\n",
    "                            validation_steps = 325 / 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d28dec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9899117]]\n",
      "[[0.00220668]]\n"
     ]
    }
   ],
   "source": [
    "imagem_teste = image.load_img(r'archive\\Tire Textures\\testing_data\\normal\\Untitled-26.jpg', target_size = (64, 64))\n",
    "\n",
    "imagem_teste = image.img_to_array(imagem_teste)\n",
    "imagem_teste/=255\n",
    "imagem_teste = np.expand_dims(imagem_teste, axis=0)\n",
    "previsao = classificador.predict(imagem_teste)\n",
    "\n",
    "base_treinamento.class_indices\n",
    "\n",
    "print(previsao)\n",
    "\n",
    "imagem_teste = image.load_img(r'archive\\Tire Textures\\testing_data\\cracked\\Untitled-26.jpg', target_size = (64, 64))\n",
    "\n",
    "imagem_teste = image.img_to_array(imagem_teste)\n",
    "imagem_teste/=255\n",
    "imagem_teste = np.expand_dims(imagem_teste, axis=0)\n",
    "previsao = classificador.predict(imagem_teste)\n",
    "\n",
    "base_treinamento.class_indices\n",
    "\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd117082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
